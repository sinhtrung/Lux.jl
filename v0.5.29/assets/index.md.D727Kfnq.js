import{_ as e,c as t,o as a}from"./chunks/framework.BwjBGjUQ.js";const d=JSON.parse('{"title":"","description":"","frontmatter":{"layout":"home","hero":{"name":"LuxDL Docs","text":"Elegant & Performant Deep Learning in JuliaLang","tagline":"A Pure Julia Deep Learning Framework putting Correctness and Performance First","actions":[{"theme":"brand","text":"Tutorials","link":"/tutorials/index"},{"theme":"alt","text":"Ecosystem","link":"/ecosystem"},{"theme":"alt","text":"API Reference ğŸ“š","link":"/api/Lux/layers"},{"theme":"alt","text":"View on GitHub","link":"https://github.com/LuxDL/Lux.jl"}],"image":{"src":"/logo.png","alt":"Lux.jl"}},"features":[{"icon":"ğŸš€","title":"Fast & Extendible","details":"Lux.jl is written in Julia itself, making it extremely extendible. <u><a href=\\"https://github.com/JuliaGPU/CUDA.jl\\">CUDA</a></u> and <u><a href=\\"https://github.com/JuliaGPU/AMDGPU.jl\\">AMDGPU</a></u> are supported first-class, with experimental support for <u><a href=\\"https://github.com/JuliaGPU/Metal.jl\\">Metal</a></u> Hardware."},{"icon":"ğŸ§‘â€ğŸ”¬","title":"SciML â¤ï¸ Lux","details":"Lux is the default choice for many <u><a href=\\"https://github.com/SciML\\">SciML</a></u> packages, including DiffEqFlux.jl, NeuralPDE.jl, and more."},{"icon":"ğŸ§©","title":"Uniquely Composable","details":"Lux.jl natively supports Arbitrary Parameter Types, making it uniquely composable with other Julia packages (and even Non-Julia packages)."},{"icon":"ğŸ§ª","title":"Well Tested","details":"Lux.jl tests every supported Automatic Differentiation Framework with every supported hardware backend against Finite Differences to prevent sneaky ğŸ› in your code."}]},"headers":[],"relativePath":"index.md","filePath":"index.md","lastUpdated":null}'),i={name:"index.md"};function n(r,l,s,o,u,c){return a(),t("div")}const m=e(i,[["render",n]]);export{d as __pageData,m as default};
